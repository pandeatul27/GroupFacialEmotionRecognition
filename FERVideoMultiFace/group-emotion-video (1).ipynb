{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7793283,"sourceType":"datasetVersion","datasetId":4016240},{"sourceId":7759395,"sourceType":"datasetVersion","datasetId":4537781}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom PIL import Image\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nimport tensorflow as tf\nimport os\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-14T02:54:42.795341Z","iopub.execute_input":"2024-03-14T02:54:42.796157Z","iopub.status.idle":"2024-03-14T02:55:00.063795Z","shell.execute_reply.started":"2024-03-14T02:54:42.796127Z","shell.execute_reply":"2024-03-14T02:55:00.062695Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-14 02:54:50.713003: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-14 02:54:50.713127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-14 02:54:50.844891: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv","metadata":{"execution":{"iopub.status.busy":"2024-03-14T02:55:00.065880Z","iopub.execute_input":"2024-03-14T02:55:00.066935Z","iopub.status.idle":"2024-03-14T02:55:00.073015Z","shell.execute_reply.started":"2024-03-14T02:55:00.066899Z","shell.execute_reply":"2024-03-14T02:55:00.072114Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE=224\ntest_transforms = transforms.Compose(\n    [\n        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T02:55:00.074499Z","iopub.execute_input":"2024-03-14T02:55:00.074879Z","iopub.status.idle":"2024-03-14T02:55:00.088040Z","shell.execute_reply.started":"2024-03-14T02:55:00.074842Z","shell.execute_reply":"2024-03-14T02:55:00.087142Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\ndevice = 'cuda' if use_cuda else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-03-14T02:55:00.090081Z","iopub.execute_input":"2024-03-14T02:55:00.090412Z","iopub.status.idle":"2024-03-14T02:55:00.141311Z","shell.execute_reply.started":"2024-03-14T02:55:00.090388Z","shell.execute_reply":"2024-03-14T02:55:00.140326Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"PATH=\"/kaggle/input/efficientnet-weights-on-vgg/enet_b0_8_best_afew.pt\"","metadata":{"execution":{"iopub.status.busy":"2024-03-14T02:55:00.142959Z","iopub.execute_input":"2024-03-14T02:55:00.143303Z","iopub.status.idle":"2024-03-14T02:55:00.149522Z","shell.execute_reply.started":"2024-03-14T02:55:00.143264Z","shell.execute_reply":"2024-03-14T02:55:00.148660Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"feature_extractor_model = torch.load(PATH)\nfeature_extractor_model.classifier=torch.nn.Identity()\nfeature_extractor_model.eval()\nfeature_extractor_model=feature_extractor_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T02:55:00.150561Z","iopub.execute_input":"2024-03-14T02:55:00.150850Z","iopub.status.idle":"2024-03-14T02:55:01.914774Z","shell.execute_reply.started":"2024-03-14T02:55:00.150828Z","shell.execute_reply":"2024-03-14T02:55:01.913926Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"emotion_to_index={\n    \"Positive\":0,\n    \"Neutral\":1,\n    \"Negative\":2\n}","metadata":{"execution":{"iopub.status.busy":"2024-03-14T02:55:01.915827Z","iopub.execute_input":"2024-03-14T02:55:01.916079Z","iopub.status.idle":"2024-03-14T02:55:01.920723Z","shell.execute_reply.started":"2024-03-14T02:55:01.916057Z","shell.execute_reply":"2024-03-14T02:55:01.919635Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"DATA_DIR='/kaggle/input/vgaf-aligned/VGAF_aligned'","metadata":{"execution":{"iopub.status.busy":"2024-03-14T02:55:01.922239Z","iopub.execute_input":"2024-03-14T02:55:01.922640Z","iopub.status.idle":"2024-03-14T02:55:01.929466Z","shell.execute_reply.started":"2024-03-14T02:55:01.922611Z","shell.execute_reply":"2024-03-14T02:55:01.928507Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_features(data_dir,cnt_frame,face_cnt):\n    videomane2features={}\n    for videoname in tqdm(os.listdir(data_dir)):\n        frame_dict=os.path.join(data_dir,videoname)\n        video_features=[]\n        cnt=0\n        for frame in os.listdir(frame_dict):\n            cnt=cnt + 1\n            if cnt==cnt_frame:\n                break;\n            face_dict=os.path.join(frame_dict,frame)\n            frame_features=[]\n            faces=[]\n            for face in os.listdir(face_dict):\n                img = Image.open(os.path.join(face_dict,face))\n                img_tensor = test_transforms(img)\n                faces.append(img_tensor)\n                \n                if img.size:\n                    faces.append(img_tensor)\n                    if len(faces)>=face_cnt:        \n                        scores = feature_extractor_model(torch.stack(faces, dim=0).to(device))\n                        scores=scores.data.cpu().numpy()\n\n                        if len(frame_features)==0:\n                            frame_features=scores\n                        else:\n                            frame_features=np.concatenate((frame_features,scores),axis=0)\n\n                        faces=[]\n                    \n            if len(faces)>0:        \n                scores = feature_extractor_model(torch.stack(faces, dim=0).to(device))\n                scores=scores.data.cpu().numpy()\n\n                if len(frame_features)==0:\n                    frame_features=scores\n                else:\n                    frame_features=np.concatenate((frame_features,scores),axis=0)\n            \n            mean_features = (np.mean(frame_features, axis=0))\n            std_features = (np.std(frame_features, axis=0))\n#             max_features = (np.max(frame_features, axis=0))\n#             min_features = (np.min(frame_features, axis=0))\n\n            overall_frame_feature=np.concatenate((mean_features,std_features),axis=None)\n            \n            video_features.append(overall_frame_feature)\n        \n        video_features=np.array(video_features)\n        mean_features = (np.mean(video_features, axis=0))\n        std_features = (np.std(video_features, axis=0))\n#         max_features = (np.max(video_features, axis=0))\n#         min_features = (np.min(video_features, axis=0))\n        overall_video_features=np.concatenate((mean_features,std_features),axis=None)\n        videomane2features[videoname]=overall_video_features\n    return videomane2features","metadata":{"execution":{"iopub.status.busy":"2024-03-14T02:55:01.930889Z","iopub.execute_input":"2024-03-14T02:55:01.931198Z","iopub.status.idle":"2024-03-14T02:55:01.945446Z","shell.execute_reply.started":"2024-03-14T02:55:01.931148Z","shell.execute_reply":"2024-03-14T02:55:01.944455Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dir=os.path.join(DATA_DIR,\"Train_faces\")\nval_dir=os.path.join(DATA_DIR,\"Val_faces\")","metadata":{"execution":{"iopub.status.busy":"2024-03-14T03:11:50.389660Z","iopub.execute_input":"2024-03-14T03:11:50.390374Z","iopub.status.idle":"2024-03-14T03:11:50.394817Z","shell.execute_reply.started":"2024-03-14T03:11:50.390341Z","shell.execute_reply":"2024-03-14T03:11:50.393868Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"videoname2features_train=get_features(train_dir,50,32)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T03:11:55.110965Z","iopub.execute_input":"2024-03-14T03:11:55.111425Z","iopub.status.idle":"2024-03-14T05:06:33.812404Z","shell.execute_reply.started":"2024-03-14T03:11:55.111396Z","shell.execute_reply":"2024-03-14T05:06:33.811411Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 2659/2659 [1:54:38<00:00,  2.59s/it]  \n","output_type":"stream"}]},{"cell_type":"code","source":"videoname2features_val=get_features(val_dir,50,32)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T05:06:33.814230Z","iopub.execute_input":"2024-03-14T05:06:33.814586Z","iopub.status.idle":"2024-03-14T05:51:40.227086Z","shell.execute_reply.started":"2024-03-14T05:06:33.814558Z","shell.execute_reply":"2024-03-14T05:51:40.226071Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 766/766 [45:06<00:00,  3.53s/it]  \n","output_type":"stream"}]},{"cell_type":"code","source":"train_labelfilename='/kaggle/input/vgaf-frames-faces/Train_labels.txt'\nval_labelfilename='/kaggle/input/vgaf-frames-faces/Val_labels.txt'","metadata":{"execution":{"iopub.status.busy":"2024-03-14T05:51:40.228461Z","iopub.execute_input":"2024-03-14T05:51:40.228835Z","iopub.status.idle":"2024-03-14T05:51:40.234037Z","shell.execute_reply.started":"2024-03-14T05:51:40.228801Z","shell.execute_reply":"2024-03-14T05:51:40.232957Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def create_dataset(videoname2features,filename):\n    x=[]\n    y=[]\n    has_face=[]\n  \n    with open(filename, mode='r') as file:\n        labels = csv.reader(file, delimiter=' ')\n        for i,row in enumerate(labels):\n            if i==0:\n                continue\n            videoname,videolabel=row[0],int(row[1])\n            \n            if videoname in videoname2features.keys():\n                video_features=videoname2features[videoname]\n                x.append(video_features)\n                has_face.append(1)\n            else:\n                x.append(np.zeros((5120,)))\n                has_face.append(0)\n            y.append(videolabel-1)\n    x=np.array(x)\n    y=np.array(y)\n    has_face=np.array(has_face)\n    print(x.shape,y.shape)\n    return x,y,has_face","metadata":{"execution":{"iopub.status.busy":"2024-03-14T05:51:40.236781Z","iopub.execute_input":"2024-03-14T05:51:40.237565Z","iopub.status.idle":"2024-03-14T05:51:40.255733Z","shell.execute_reply.started":"2024-03-14T05:51:40.237528Z","shell.execute_reply":"2024-03-14T05:51:40.254830Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"x_train, y_train, has_faces_train = create_dataset(videoname2features_train,train_labelfilename)\nx_test, y_test, has_faces_test = create_dataset(videoname2features_val,val_labelfilename)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T05:51:40.256827Z","iopub.execute_input":"2024-03-14T05:51:40.257084Z","iopub.status.idle":"2024-03-14T05:51:40.321392Z","shell.execute_reply.started":"2024-03-14T05:51:40.257063Z","shell.execute_reply":"2024-03-14T05:51:40.320383Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(2661, 5120) (2661,)\n(766, 5120) (766,)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn import svm,metrics,preprocessing","metadata":{"execution":{"iopub.status.busy":"2024-03-14T05:51:40.322456Z","iopub.execute_input":"2024-03-14T05:51:40.322738Z","iopub.status.idle":"2024-03-14T05:51:40.858475Z","shell.execute_reply.started":"2024-03-14T05:51:40.322713Z","shell.execute_reply":"2024-03-14T05:51:40.857521Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"x_train_norm=preprocessing.normalize(x_train,norm='l2')\nx_test_norm=preprocessing.normalize(x_test,norm='l2')","metadata":{"execution":{"iopub.status.busy":"2024-03-14T05:51:40.859723Z","iopub.execute_input":"2024-03-14T05:51:40.860537Z","iopub.status.idle":"2024-03-14T05:51:40.955440Z","shell.execute_reply.started":"2024-03-14T05:51:40.860502Z","shell.execute_reply":"2024-03-14T05:51:40.954262Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"clf = svm.SVC(kernel='rbf',C=1.9)\nif True:    \n    clf.fit(x_train_norm[has_faces_train==1], y_train[has_faces_train==1])\n    y_pred = clf.predict(x_test_norm)\nelse:\n    clf.fit(x_train[has_faces_train==1], y_train[has_faces_train==1])\n    y_pred = clf.predict(x_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test[has_faces_test==1], y_pred[has_faces_test==1]))\nprint(\"Complete accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-03-14T05:51:40.956602Z","iopub.execute_input":"2024-03-14T05:51:40.956903Z","iopub.status.idle":"2024-03-14T05:52:12.881993Z","shell.execute_reply.started":"2024-03-14T05:51:40.956876Z","shell.execute_reply":"2024-03-14T05:52:12.880966Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Accuracy: 0.6096605744125326\nComplete accuracy: 0.6096605744125326\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ndef confusion_matrix(y_pred,y_val):\n    yhat_valid = y_pred\n    val_labels_onehot = tf.keras.utils.to_categorical(y_val)\n    print(f'total wrong validation predictions: {np.sum(np.argmax(val_labels_onehot, axis=1) != yhat_valid)}\\n\\n')\n    print(classification_report(np.argmax(val_labels_onehot, axis=1), yhat_valid))","metadata":{"execution":{"iopub.status.busy":"2024-03-14T05:52:12.883316Z","iopub.execute_input":"2024-03-14T05:52:12.883653Z","iopub.status.idle":"2024-03-14T05:52:12.889697Z","shell.execute_reply.started":"2024-03-14T05:52:12.883625Z","shell.execute_reply":"2024-03-14T05:52:12.888617Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(\"Confusion matrix:\\n\")\nconfusion_matrix(y_pred[has_faces_test==1], y_test[has_faces_test==1])","metadata":{"execution":{"iopub.status.busy":"2024-03-14T05:52:12.892762Z","iopub.execute_input":"2024-03-14T05:52:12.893150Z","iopub.status.idle":"2024-03-14T05:52:12.913728Z","shell.execute_reply.started":"2024-03-14T05:52:12.893116Z","shell.execute_reply":"2024-03-14T05:52:12.912881Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Confusion matrix:\n\ntotal wrong validation predictions: 299\n\n\n              precision    recall  f1-score   support\n\n           0       0.78      0.61      0.69       302\n           1       0.60      0.57      0.59       280\n           2       0.46      0.67      0.55       184\n\n    accuracy                           0.61       766\n   macro avg       0.62      0.62      0.61       766\nweighted avg       0.64      0.61      0.62       766\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Overall Confusion matrix:\\n\")\nconfusion_matrix(y_pred, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T05:52:12.914774Z","iopub.execute_input":"2024-03-14T05:52:12.915051Z","iopub.status.idle":"2024-03-14T05:52:12.928586Z","shell.execute_reply.started":"2024-03-14T05:52:12.915026Z","shell.execute_reply":"2024-03-14T05:52:12.927728Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Overall Confusion matrix:\n\ntotal wrong validation predictions: 299\n\n\n              precision    recall  f1-score   support\n\n           0       0.78      0.61      0.69       302\n           1       0.60      0.57      0.59       280\n           2       0.46      0.67      0.55       184\n\n    accuracy                           0.61       766\n   macro avg       0.62      0.62      0.61       766\nweighted avg       0.64      0.61      0.62       766\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}